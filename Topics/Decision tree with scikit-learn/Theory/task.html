<div class="step-text">
<p>In this topic, you will learn how to implement a decision tree classifier with <code class="language-python">scikit-learn</code>. In essence, the decision tree is a flowchart-like structure consisting of many conditions - decision rules that are generated during the learning process.</p><p>We will learn how to train a decision tree and explore the parameters that affect the quality of the model.</p><h5 id="loading-data">Loading data</h5><p>We'll use the <a href="http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)" rel="noopener noreferrer nofollow" target="_blank">Mines vs Rocks dataset.</a> The dataset contains 208 samples of signals recorded by sonar from two object classes: rocks and mines. In the first 60 columns, you can see wavelengths that the sonar received from different angles. The label column contains two categorical values: <code class="language-python">0</code> - mine, <code class="language-python">1</code> - rock.</p><p>First, let's load the data and split it into train and test sets:</p><pre><code class="language-python">import pandas as pd
from sklearn.model_selection import train_test_split

link = "http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"
df_sonar = pd.read_csv(link, header=None)
df_sonar[60].replace(['M','R'], [0, 1], inplace=True)

X = df_sonar.drop(60, axis=1)
y = df_sonar[60]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=34)

df_sonar.head()
</code></pre><p>Output (the columns from 5th to 57th are hidden):</p><pre><code class="language-no-highlight">   0	   1	  2      3    ...  58     59	60
0 0.0200 0.0371	0.0428 0.0207 ... 0.0084 0.0032  1
1 0.0453 0.0523	0.0843 0.0689 ... 0.0049 0.0044  1
2 0.0262 0.0582	0.1099 0.1083 ... 0.0164 0.0078  1
3 0.0100 0.0171	0.0623 0.0205 ... 0.0044 0.0117  1

</code></pre><h5 id="fitting-a-model">Fitting a model</h5><p>To train a model, we will use the <code class="language-python">DecisionTreeClassifier</code> class from sklearn. Let's create a decision tree model:</p><pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier

# Creating a DecisionTreeClassifier object
clf = DecisionTreeClassifier(random_state=34)

# Training a model
clf = clf.fit(X_train, y_train)
# &gt;&gt;&gt; DecisionTreeClassifier(random_state=34)</code></pre><p> </p><p></p><div class="alert alert-primary"><p>As you can see, we've defined a <code class="language-python">random state</code> parameter for our model. What does this mean? The random state ensures that the results your model obtains are reproducible. Try it yourself: train decision tree models with different random states and then compare the predictions.</p></div><p></p><p> </p><p>After the model has been fit, we can access the following properties of the model:</p><ul><li><p><code class="language-python">classes_</code> - a list of class labels.</p></li><li><p><code class="language-python">n_features_</code> - the number of features.</p></li><li><p><code class="language-python">feature_importances_</code> - feature importances that are calculated as the decrease in node impurity weighted by the probability of reaching that node. The higher the value, the more important the feature is.</p></li></ul><p>You could read about all the other model properties in the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" rel="noopener noreferrer nofollow" target="_blank">sklearn documentation</a>.</p><h5 id="making-predictions">Making predictions</h5><p>Now we will make a prediction for the training data. Let's pick some record from the dataset (for example, <code class="language-python">X[55]</code>) and compare the prediction result with the target value from the dataset.</p><pre><code class="language-python">pred_train = clf.predict(X_train)
prediction = pred_train[55]
result = y_train.iloc[55]
print(prediction, result)
# &gt;&gt;&gt; 1 1</code></pre><p>See, the prediction result and the value from the target set are the same. Not bad! But let's take a look at the big picture. In this topic, we will use the <code class="language-python">score()</code> method to evaluate our model. It returns the mean accuracy for train and test data.</p><pre><code class="language-python">train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)
print("Accuracy on train set: {}".format(train_score))
print("Accuracy on test set: {}".format(round(test_score, 3)))

# &gt;&gt;&gt; Accuracy on train set: 1.0
# &gt;&gt;&gt; Accuracy on test set: 0.725</code></pre><p>The result of 72% is considered to be quite good. There are other ways to evaluate a decision tree model, but we won't go in-depth into decision tree evaluation metrics in this topic.</p><h5 id="decision-tree-parameters">Decision tree parameters</h5><p>Above, we've created a <code class="language-python">DecisionTreeClassifier</code> object without passing any parameters. However, the <code class="language-python">DecisionTreeClassifier</code> class offers a lot of possibilities to tune our decision tree model and make it perform better. Let's list the most essential parameters:</p><ul><li><p><code class="language-python">criterion</code> (default: <code class="language-python">'gini'</code>, <code class="language-python">'gini'</code>/ <code class="language-python">'entropy'</code>/ <code class="language-python">'log_loss'</code>)</p></li></ul><p>From the previous topic, you know that there are different criteria for finding the best split of the data in each node. In the <code class="language-python">criterion</code> parameter, you can specify to the classifier which criterion it should apply to measure the quality of a split. Supported criteria are <code class="language-python">'gini'</code> for the Gini impurity and both <code class="language-python">'entropy'</code> and <code class="language-python">'log_loss'</code> for the information gain. By default, the classifier uses Gini impurity, so let's set it to <code class="language-python">'entropy'</code>.</p><pre><code class="language-python">clf = DecisionTreeClassifier(criterion='entropy', random_state=34)
clf.fit(X_train, y_train)
# &gt;&gt;&gt; DecisionTreeClassifier(criterion='entropy', random_state=34)

print(clf.score(X_test, y_test))
# &gt;&gt;&gt; 0.7681159420289855</code></pre><p>By splitting based on entropy criterion we gained a better accuracy value - 0.725 for <code class="language-python">gini</code> vs 0.768 for <code class="language-python">entropy</code>. </p><ul><li><p><code class="language-python">max_depth</code> (default: <code class="language-python">None</code>, <code class="language-python">int</code>)</p></li></ul><p>The next parameter - <code class="language-python">max_depth</code> - is the maximum depth of a tree, that is the length of the longest path from the root to a leaf. It's one of the parameters responsible for stopping the splitting. First, let's find the depth of our model. For this purpose, our classifier has the function <code class="language-python">get_depth()</code>. </p><pre><code class="language-python">clf.get_depth()
# &gt;&gt;&gt; 5</code></pre><p>Let's pass <code class="language-python">2</code> to <code class="language-python">max_depth</code> and see what happens:</p><pre><code class="language-python">clf = DecisionTreeClassifier(random_state=34, max_depth=2)
clf.fit(X_train, y_train)

# For training data:
print(clf.score(X_train, y_train))
# &gt;&gt;&gt; 0.7697841726618705

# For test set:
print(clf.score(X_test, y_test))
# &gt;&gt;&gt; 0.6231884057971014</code></pre><p>The performance of our model on both the training and test data has worsened; this is because our model was underfitted. In such a setup, the tree can't have a depth greater than 2. This leads to our model not being complex enough to capture the relations between features and the target variable. As a result, it performs worse on both the training and test data. However, it can be detrimental in both ways: a higher value of <code class="language-python">max_depth</code> may cause overfitting. In this case, the model has learned too well to predict on the training data and has lost the ability to generalize predictions. So, we'd get an excellent score on the training data and a much less satisfactory score on the test data.</p><p>The quality of the prediction depends on the tree's depth. So, the task is to find the depth at which there will be the smallest gap between the scores on the test and train data. For now, we can simply do this by training models with different <code class="language-python">max_depth</code> values and comparing model performances on the train and test data. Later, you'll learn about more advanced and efficient techniques to find the best parameters.</p><ul><li><p><code class="language-python">min_samples_split</code><strong> </strong>&amp;<strong> </strong><code class="language-python">min_samples_leaf</code></p></li></ul><p><code class="language-python">max_depth</code> is not the only way to tell a classifier when it must stop splitting. We can also set a minimum number of samples required for splitting. That is, if there are less than a certain number of samples in a node, the split won't happen. To set this minimum number of samples, we should specify the <code class="language-python">min_samples_split</code> parameter.</p><p>Another parameter, <code class="language-python">min_samples_leaf</code>, specifies the minimum number of samples required to be at a leaf node. In other words, a split won't happen if there isn't a certain number of samples to be both in the left and right branches after splitting.</p><ul><li><p><code class="language-python">max_features</code> (default: <code class="language-python">None</code>, <code class="language-python">int</code>, <code class="language-python">float</code> or from <code class="language-python">{'auto', 'sqrt', 'log2'}</code>)</p></li></ul><p>The last but not least important parameter is <code class="language-python">max_features</code>. It determines the maximum number of features to be considered while looking for the best split. Not only an integer or a float number but also <code class="language-python">sqrt</code>(square root) or <code class="language-python">log2</code> (binary logarithm) can be passed to the parameter. When should we specify <code class="language-python">max_features</code>? It's suitable when the dataset is too big and we wish to reduce the training time of our model, which directly depends on the number of features.</p><h5 id="conclusion">Conclusion</h5><p>In this topic, we learned how to:</p><ul><li><p>Train a decision tree classifier;</p></li><li><p>Change a criterion that measures the quality of a split;</p></li><li><p>Control the tree's depth to avoid overfitting;</p></li><li><p>Limit the number of features to optimize our model.</p></li></ul><p>You can find more information about the <code class="language-python">DecisionTreeClassifier</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener noreferrer nofollow" target="_blank">in the documentation</a>.</p>
</div>